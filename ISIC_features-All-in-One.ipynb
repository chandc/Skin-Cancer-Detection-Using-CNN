{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/danielchan/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import h5py\n",
    "import numpy as np\n",
    "import math\n",
    "import keras \n",
    "import tensorflow as tf\n",
    "np.random.seed(617)\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Convolution2D, MaxPooling2D, ZeroPadding2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense, Input\n",
    "from keras.optimizers import SGD, Adam\n",
    "from keras.layers.normalization import BatchNormalization\n",
    "\n",
    "\n",
    "from time import time\n",
    "\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.8.0\n",
      "2.2.0\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)\n",
    "print(keras.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/danielchan/Dropbox/ISIC2017\n",
      "/home/danielchan/Downloads/Training_Data_Sq_orig_added_images\n"
     ]
    }
   ],
   "source": [
    "import os, sys\n",
    "import shutil\n",
    "\n",
    "current_dir = os.getcwd()\n",
    "HOME_DIR = current_dir\n",
    "\n",
    "\n",
    "#train_data_dir = '/home/danielchan/Dropbox/ISIC2017/ISIC-2017_Test_Data'\n",
    "#train_data_dir = '/home/danielchan/Downloads/train_1'\n",
    "#train_data_dir = '/home/danielchan/Dropbox/ISIC2017/ISIC-2017_Validation_Data'\n",
    "\n",
    "#prefix = 'Orig_test_features_ISIC_'\n",
    "#prefix = 'Arg2_train_features_ISIC_'\n",
    "#prefix = 'Orig_valid_features_ISIC_'\n",
    "#prefix = 'Arg3_valid_features_ISIC_'\n",
    "#prefix = 'Arg2_valid_features_ISIC_'\n",
    "\n",
    "#train_data_dir='/home/danielchan/Downloads/train'\n",
    "\n",
    "\n",
    "#train_data_dir= '/home/danielchan/Dropbox/ISIC2017/ISIC-2017_Training_Data'\n",
    "#train_data_dir = '/home/danielchan/Downloads/ISIC-2017_Training_Data'\n",
    "\n",
    "#prefix = 'Arg4_train_features_ISIC_'\n",
    "#prefix = 'Orig_train_features_ISIC_'\n",
    "#train_data_dir = '/home/danielchan/Downloads/Test_square'\n",
    "#prefix = 'test_v2_sq_features_ISIC_'\n",
    "\n",
    "train_data_dir = '/home/danielchan/Downloads/Train_Sq_3000'\n",
    "prefix = 'Arg3000_train_features_ISIC_'\n",
    "\n",
    "train_data_dir = '/home/danielchan/Downloads/Validation_Orig_Sq'\n",
    "prefix = 'ArgSq_valid_features_ISIC_'\n",
    "\n",
    "train_data_dir = '/home/danielchan/Downloads/Test_Data_Sq_orig'\n",
    "prefix = 'Sq_orig_test_features_ISIC_'\n",
    "\n",
    "train_data_dir = '/home/danielchan/Downloads/Validation_Data_Sq_orig'\n",
    "prefix = 'Sq_orig_valid_features_ISIC_'\n",
    "\n",
    "\n",
    "train_data_dir = '/home/danielchan/Downloads/Training_Data_Sq_orig'\n",
    "prefix = 'Sq_orig_train_features_ISIC_'\n",
    "\n",
    "train_data_dir = '/home/danielchan/Downloads/Training_Data_Sq_orig_added_images'\n",
    "prefix = 'Sq_orig_added_images_train_features_ISIC_'\n",
    "\n",
    "print (HOME_DIR)\n",
    "print (train_data_dir)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vgg16_model():\n",
    "    from keras.applications.vgg16 import VGG16\n",
    "    from keras.applications.vgg16 import preprocess_input\n",
    "    img_width, img_height = 224,224\n",
    "    print ('using the VGG16 model')\n",
    "    input_shape=(img_width, img_height, 3)\n",
    "    img_input = Input(shape=input_shape)\n",
    "    base_model = VGG16(include_top=False, weights='imagenet', input_tensor=img_input)\n",
    "    print('VGG16 model loaded')\n",
    "    return base_model, img_width, img_height, preprocess_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resnet50_model():\n",
    "    from keras.applications.resnet50 import ResNet50\n",
    "    from keras.applications.resnet50 import preprocess_input\n",
    "    img_width, img_height = 224,224\n",
    "    print ('using the ResNet50 model')\n",
    "    input_shape=(img_width, img_height, 3)\n",
    "    img_input = Input(shape=input_shape)\n",
    "    base_model = ResNet50(include_top=False, weights='imagenet', input_tensor=img_input)\n",
    "    print('ResNet50 model loaded')\n",
    "    return base_model, img_width, img_height, preprocess_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def incp_v3_model(): \n",
    "    from keras.applications.inception_v3 import InceptionV3\n",
    "    from keras.applications.inception_v3 import preprocess_input,decode_predictions\n",
    "    img_width, img_height = 299,299\n",
    "    print ('using the InceptionV3 model')\n",
    "    input_shape=(img_width, img_height, 3)\n",
    "    img_input = Input(shape=input_shape)\n",
    "    base_model = InceptionV3(include_top=False, weights='imagenet', input_tensor=img_input)\n",
    "    print('InceptionV3 model loaded')\n",
    "    return base_model, img_width, img_height, preprocess_input    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def xcp_model(): \n",
    "    from keras.applications.xception import Xception\n",
    "    from keras.applications.xception import preprocess_input,decode_predictions\n",
    "    img_width, img_height = 299,299\n",
    "    print ('using the Xception model')\n",
    "    input_shape=(img_width, img_height, 3)\n",
    "    img_input = Input(shape=input_shape)\n",
    "    base_model = Xception(include_top=False, weights='imagenet', input_tensor=img_input)\n",
    "    print('Xception model loaded')\n",
    "    return base_model, img_width, img_height, preprocess_input "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def InceptionResNet_model():     \n",
    "    from keras.applications.inception_resnet_v2 import InceptionResNetV2\n",
    "    from keras.applications.inception_resnet_v2 import preprocess_input,decode_predictions\n",
    "    img_width, img_height = 299,299\n",
    "    print ('using the InceptionResNetV2 model')\n",
    "    input_shape=(img_width, img_height, 3)\n",
    "    img_input = Input(shape=input_shape)\n",
    "    base_model = InceptionResNetV2(include_top=False, weights='imagenet', input_tensor=img_input)\n",
    "    print('InceptionResNetV2 model loaded')\n",
    "    return base_model, img_width, img_height, preprocess_input "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vgg19_model():\n",
    "    from keras.applications.vgg19 import VGG19\n",
    "    from keras.applications.vgg19 import preprocess_input\n",
    "    img_width, img_height = 224,224\n",
    "    print ('using the VGG19 model')\n",
    "    input_shape=(img_width, img_height, 3)\n",
    "    img_input = Input(shape=input_shape)\n",
    "    base_model = VGG19(include_top=False, weights='imagenet', input_tensor=img_input)\n",
    "    print('VGG19 model loaded')\n",
    "    return base_model, img_width, img_height, preprocess_input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = { 'VGG16': vgg16_model,\n",
    "           'RES50': resnet50_model,\n",
    "           'INCPV3': incp_v3_model,\n",
    "           'VGG19':  vgg19_model,\n",
    "           'IRV2': InceptionResNet_model,\n",
    "            'XCP':  xcp_model}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "writing the data to  Sq_orig_added_images_train_features_ISIC_VGG16\n",
      "using the VGG16 model\n",
      "VGG16 model loaded\n",
      "define preprocessing function\n",
      "/home/danielchan/Downloads/Training_Data_Sq_orig_added_images\n",
      "Found 5000 images belonging to 3 classes.\n",
      "s,bacth,size=  5000 64 79\n",
      "number of images:  5000\n",
      "number of images for each class: \n",
      "(array([0, 1, 2], dtype=int32), array([1374, 2372, 1254]))\n",
      "{'melanoma': 0, 'nevus': 1, 'seborrheic_keratosis': 2}\n",
      "/home/danielchan/Dropbox/ISIC2017\n",
      "/home/danielchan/Dropbox/ISIC2017\n",
      "start generating training data\n",
      "79/79 [==============================] - 17s 211ms/step\n",
      "time to determine train features:  17.100415229797363\n",
      "training file written in  Sq_orig_added_images_train_features_ISIC_VGG16  shape=  (5000, 7, 7, 512)\n",
      "writing the data to  Sq_orig_added_images_train_features_ISIC_RES50\n",
      "using the ResNet50 model\n",
      "ResNet50 model loaded\n",
      "define preprocessing function\n",
      "/home/danielchan/Downloads/Training_Data_Sq_orig_added_images\n",
      "Found 5000 images belonging to 3 classes.\n",
      "s,bacth,size=  5000 64 79\n",
      "number of images:  5000\n",
      "number of images for each class: \n",
      "(array([0, 1, 2], dtype=int32), array([1374, 2372, 1254]))\n",
      "{'melanoma': 0, 'nevus': 1, 'seborrheic_keratosis': 2}\n",
      "/home/danielchan/Dropbox/ISIC2017\n",
      "/home/danielchan/Dropbox/ISIC2017\n",
      "start generating training data\n",
      "79/79 [==============================] - 16s 201ms/step\n",
      "time to determine train features:  16.8922278881073\n",
      "training file written in  Sq_orig_added_images_train_features_ISIC_RES50  shape=  (5000, 7, 7, 2048)\n",
      "writing the data to  Sq_orig_added_images_train_features_ISIC_INCPV3\n",
      "using the InceptionV3 model\n",
      "InceptionV3 model loaded\n",
      "define preprocessing function\n",
      "/home/danielchan/Downloads/Training_Data_Sq_orig_added_images\n",
      "Found 5000 images belonging to 3 classes.\n",
      "s,bacth,size=  5000 64 79\n",
      "number of images:  5000\n",
      "number of images for each class: \n",
      "(array([0, 1, 2], dtype=int32), array([1374, 2372, 1254]))\n",
      "{'melanoma': 0, 'nevus': 1, 'seborrheic_keratosis': 2}\n",
      "/home/danielchan/Dropbox/ISIC2017\n",
      "/home/danielchan/Dropbox/ISIC2017\n",
      "start generating training data\n",
      "79/79 [==============================] - 20s 253ms/step\n",
      "time to determine train features:  21.44573140144348\n",
      "training file written in  Sq_orig_added_images_train_features_ISIC_INCPV3  shape=  (5000, 8, 8, 2048)\n",
      "writing the data to  Sq_orig_added_images_train_features_ISIC_VGG19\n",
      "using the VGG19 model\n",
      "VGG19 model loaded\n",
      "define preprocessing function\n",
      "/home/danielchan/Downloads/Training_Data_Sq_orig_added_images\n",
      "Found 5000 images belonging to 3 classes.\n",
      "s,bacth,size=  5000 64 79\n",
      "number of images:  5000\n",
      "number of images for each class: \n",
      "(array([0, 1, 2], dtype=int32), array([1374, 2372, 1254]))\n",
      "{'melanoma': 0, 'nevus': 1, 'seborrheic_keratosis': 2}\n",
      "/home/danielchan/Dropbox/ISIC2017\n",
      "/home/danielchan/Dropbox/ISIC2017\n",
      "start generating training data\n",
      "79/79 [==============================] - 18s 224ms/step\n",
      "time to determine train features:  18.29454731941223\n",
      "training file written in  Sq_orig_added_images_train_features_ISIC_VGG19  shape=  (5000, 7, 7, 512)\n",
      "writing the data to  Sq_orig_added_images_train_features_ISIC_IRV2\n",
      "using the InceptionResNetV2 model\n",
      "InceptionResNetV2 model loaded\n",
      "define preprocessing function\n",
      "/home/danielchan/Downloads/Training_Data_Sq_orig_added_images\n",
      "Found 5000 images belonging to 3 classes.\n",
      "s,bacth,size=  5000 64 79\n",
      "number of images:  5000\n",
      "number of images for each class: \n",
      "(array([0, 1, 2], dtype=int32), array([1374, 2372, 1254]))\n",
      "{'melanoma': 0, 'nevus': 1, 'seborrheic_keratosis': 2}\n",
      "/home/danielchan/Dropbox/ISIC2017\n",
      "/home/danielchan/Dropbox/ISIC2017\n",
      "start generating training data\n",
      "18/79 [=====>........................] - ETA: 39s"
     ]
    }
   ],
   "source": [
    "\n",
    "for m in models:\n",
    "    train_output = prefix + str(m)\n",
    "    print ('writing the data to ',train_output)\n",
    "    model, img_width, img_height, preprocess_input = models[m]( )\n",
    "    print ('define preprocessing function')\n",
    "    datagen = ImageDataGenerator(preprocessing_function=preprocess_input)  \n",
    "    print (train_data_dir)\n",
    "    batch   = 64\n",
    "    start = time()\n",
    "    generator = datagen.flow_from_directory(\n",
    "            train_data_dir,\n",
    "            target_size=(img_width, img_height),\n",
    "            batch_size=batch,\n",
    "            class_mode='categorical',\n",
    "            shuffle=False)\n",
    "    s = len(generator.filenames)\n",
    "    size = int(math.ceil(s/ batch)) \n",
    "    print ('s,bacth,size= ',s,batch,size)\n",
    "    print ('number of images: ',len(generator.classes))\n",
    "    print ('number of images for each class: ')\n",
    "    print (np.unique(generator.classes,return_counts=True))\n",
    "    print (generator.class_indices)\n",
    "    \n",
    "    %cd '/home/danielchan/Dropbox/ISIC2017'\n",
    "    print (os.getcwd())\n",
    "\n",
    "    print ('start generating training data')            \n",
    "    start = time()\n",
    "\n",
    "    bottleneck_features_train = model.predict_generator(generator,steps=size, verbose=1, \n",
    "                                                        workers=6, use_multiprocessing=True)\n",
    "\n",
    "    print ('time to determine train features: ',time() - start)\n",
    "    output = train_output\n",
    "\n",
    "    np.savez(open(output, 'wb'), features=bottleneck_features_train, labels=generator.classes)\n",
    "    print ('training file written in ',train_output,' shape= ',bottleneck_features_train.shape)\n",
    "\n",
    "    \n",
    "    \n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
